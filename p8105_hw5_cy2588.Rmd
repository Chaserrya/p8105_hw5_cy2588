---
title: "p8105_hw5_cy2588"
author: "Chufeng Yang"
date: "2020/11/14"
output: github_document
---

```{r setup, include = FALSE}
library(tidyverse)
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


## Problem 1

### Solution 1
Read in the data.

```{r}
homicide_df = 
  read_csv("p1_data/homicide-data.csv") %>% 
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved",
    )
  ) %>% 
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL")
```
Summarize
```{r}
aggregate_df = 
  homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    hom_total = n(),
    hom_unsolved = sum(resolved == "unsolved")
  )
```

prop test for a single city

```{r}
prop.test(
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_unsolved), 
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_total)) %>% 
  broom::tidy()
```

Iterate

```{r}
results_df = 
  aggregate_df %>% 
  mutate(
    prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)),
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
  ) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high)
```

Create a plot
```{r}
results_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

### Solution 2

Clean the data
```{r, error = TRUE}
homicide_df_2 = 
  read_csv("p1_data/homicide-data.csv") %>% 
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved",
    )
  ) %>% 
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL") %>% 
  nest(data = resolved)
```
Build a function of prop test
```{r, error = TRUE}
city_prop_test = function(df) {
  
  n_unsovled = as.numeric(summarize(df,sum(resolved == "unsolved")))
  n_total = as.numeric(summarize(df,n()))
  
  prop.test(n_unsovled, n_total)
  
}
```

map function with data



```{r, error = TRUE}
results_df_2 = 
  homicide_df_2 %>% 
  mutate(
    prop_tests_2 = map(homicide_df_2$data, city_prop_test),
    tidy_tests_2 = map(.x = prop_tests_2, ~broom::tidy(.x))
) %>%
  select(-prop_tests_2) %>% 
  unnest(tidy_tests_2) %>% 
  select(city_state, estimate, conf.low, conf.high)
```

Create a plot
```{r, error = TRUE}
results_df_2 %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

## Problem 2

Start with a dataframe containing data from all participants
```{r, error = TRUE}
path_df = 
  tibble(
    path = list.files("p2_data"),
  )
```

Iterate over file names and read in data
```{r}
lda_data = 
  path_df %>%
  mutate(
    path = str_c("p2_data/", path),
    data = map(path, read.csv)) %>%
  unnest(data)
lda_data
```

Tidy the result
```{r}
lda_data_tidy = 
  lda_data %>%
  mutate(
    path = str_remove_all(path,".csv")
  )%>%
  separate(path, into = c("arm","id"), sep = 11)%>%
  mutate(
    arm = str_remove_all(arm, "p2_data/"),
    id = str_remove_all(id, "_"),
    arm = str_replace(arm,"con","control"),
    arm = str_replace(arm,"exp","experiment")
  )%>%
  pivot_longer(
    week_1:week_8,
    names_prefix = "week_",
    names_to = "week",
    values_to = "observations"
  )%>%
  mutate(week = as.numeric(week))
lda_data_tidy
```

Make a spaghetti plot
```{r}
lda_data_tidy %>%
  unite("arm_id",c(arm,id), sep = "_", remove = F)%>%
  ggplot(aes(x = week,
             y = observations))+
  geom_point(aes(color = arm,
                group = id),
             alpha = .5,
             size = .5)+
  geom_path(aes(colour = arm, 
                group = arm_id),
            alpha = .5)+
  geom_smooth(aes(colour = arm), se = F)
```

From the plot above, we could find that the observations of experimental group keep increasing since week 1, and observations of control group are basically  stable. Then we noted that the observations of both groups are close, and observations of experimental group become higher than control group over time.  

## Problem3

Set mu = 0
```{r}
set.seed(1)
sim_t = function(n = 30, mu, sigma = 5){

  sim_data_0 = tibble( 
  x = rnorm(n, mean = mu, sd = sigma)
  )
sim_data_0 %>% 
    summarize(
      mu_hat = mean(x),
      p_value = t.test(x, conf.level = 0.95) %>% broom::tidy()%>% pull(p.value),
      mu = mu
    )
  
}

output = vector("list", 5000)

for (i in 1:5000) {
  output[[i]] = sim_t(mu = 0)
}

sim_results = bind_rows(output)
```

Repeat for mu = 1,2,3,4,5,6
```{r}
set.seed(1)
sim = function(n = 30, mu, sigma = 5){
  
  output_all = vector("list", 5000)
  for (i in 1:5000) {
  output_all[[i]] = sim_t(mu = mu)
  }
  sim_results_all = bind_rows(output_all)
}

output_set = vector("list", 6)

for (i in 1:6) {
  output_set[[i]] = sim(mu = i)
}

sim_total = bind_rows(output_set)
```

make plot of the power
```{r message=F, warning=F}
sim_total %>% 
  mutate(mu = as.factor(mu)) %>% 
  filter(p_value <= 0.05) %>% 
  count(mu)%>%
ggplot(aes(x = mu, y = n/5000, fill = mu)) +
  geom_bar(stat="identity", width = .5) +
  labs(
    x = "true value of μ",
    y = "power of the test",
    title = "power plot by different μ"
    )
```

As we known the true value of μ, when null is constant, the change in effect sizes follows the ture value of μ. Then according to the plot, we could find the power of the test increased when our true value of μ increasing(effect size increasing). When true value of μ equal or greater than 5, power of the test reached maximum.  

plot of average estimate and rejected
```{r message=F, warning=F}
mean_data = sim_total %>% 
  group_by(mu) %>% 
  summarize( mean_mu = mean(mu_hat))%>% 
  mutate(group = "all") 
rej_mean_data = sim_total %>% 
  filter(p_value <= 0.05) %>% 
  group_by(mu) %>% 
  summarize( mean_mu = mean(mu_hat))%>% 
  mutate(group = "rejected")
p3_plot_data = bind_rows(mean_data, rej_mean_data)

 ggplot(p3_plot_data, aes(x = mu, y = mean_mu, group = group, color = group)) +
  geom_point(aes(color = group), alpha = .5, size = 3) +
  geom_smooth(alpha = .5, size = 0.5) +
  labs(
    x = "true value of μ",
    y = "average estimate",
    title = "average estimate by different μ"
    )
```

#### Is the sample average of μ^ across tests for which the null is rejected approximately equal to the true value of μ? Why or why not?  
According to the plot, we could find that the  sample average of μ_hat for which the null is rejected approximately equal to the true value of μ when the true value of μ is greater than 3.   
Because when the effect size of μ increased, the power of ttest increased, so the probability of rejecting the null hypothesis when it is false increased, and the sample average of μ^ will close to the true value. But when the power of test is relatively lower, some tests for which the null is false will fail to reject and cause the sample average of μ^ deviate from the true values.  
(Here sample average of μ^ is greater than true value because for those tests we fail to reject the null, their sample mean is relatively smaller(closer to 0), so the sample average of μ^ across tests for which the null is rejected will get greater. )






















